{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn import metrics\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('classic')\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(16,10)}, font_scale=1.3)\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms.tree.branchings import maximum_branching\n",
    "import scipy.stats as stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_confounders_2011 = pd.read_csv('processed_data/full_dataset_confounders_2011.csv')\n",
    "full_dataset_confounders_2012 = pd.read_csv('processed_data/full_dataset_confounders_2012.csv')\n",
    "full_dataset_confounders_2013 = pd.read_csv('processed_data/full_dataset_confounders_2013.csv')\n",
    "\n",
    "def convert_absolutes_to_percentages(dataset):\n",
    "    df = dataset.copy()\n",
    "    df['Aged 16-64 Percentage'] = df[\"Aged 16-64\"] / (df[\"Aged 16-64\"] + df[\"Aged 0-15\"] + df[\"Aged 65+\"]) * 100\n",
    "    df['Aged 0-15 Percentage'] = df[\"Aged 0-15\"] / (df[\"Aged 16-64\"] + df[\"Aged 0-15\"] + df[\"Aged 65+\"]) * 100\n",
    "    df['Aged 65+ Percentage'] = df[\"Aged 65+\"] / (df[\"Aged 16-64\"] + df[\"Aged 0-15\"] + df[\"Aged 65+\"]) * 100\n",
    "    df[\"Percentage of Full-time employees\"] = df[\"Number of Full-time employees\"] / (df[\"Number of Part-time employees\"] + df[\"Number of Full-time employees\"]) * 100\n",
    "    df[\"Percentage of Part-time employees\"] = df[\"Number of Part-time employees\"] / (df[\"Number of Part-time employees\"] + df[\"Number of Full-time employees\"]) * 100\n",
    "    df.drop(['Aged 0-15', 'Aged 16-64', 'Aged 65+', 'Number of Full-time employees', 'Number of Part-time employees'], axis=1, inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    " \n",
    "full_dataset_confounders_2011 = convert_absolutes_to_percentages(full_dataset_confounders_2011)\n",
    "full_dataset_confounders_2012 = convert_absolutes_to_percentages(full_dataset_confounders_2012)\n",
    "full_dataset_confounders_2013 = convert_absolutes_to_percentages(full_dataset_confounders_2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>osward</th>\n",
       "      <th>QUANTITY</th>\n",
       "      <th>Area that is greenspace</th>\n",
       "      <th>Percentage homes with deficiency in access to nature</th>\n",
       "      <th>DWP Working-age client group (rates)</th>\n",
       "      <th>Employment and support allowance claimants</th>\n",
       "      <th>Housing Benefit rates</th>\n",
       "      <th>Income Support Claimants</th>\n",
       "      <th>Incapacity Benefit Claimants</th>\n",
       "      <th>JSA Claimant Rate</th>\n",
       "      <th>...</th>\n",
       "      <th>outdoor_count</th>\n",
       "      <th>pub_count</th>\n",
       "      <th>skate_count</th>\n",
       "      <th>theatre_count</th>\n",
       "      <th>total_count</th>\n",
       "      <th>Aged 16-64 Percentage</th>\n",
       "      <th>Aged 0-15 Percentage</th>\n",
       "      <th>Aged 65+ Percentage</th>\n",
       "      <th>Percentage of Full-time employees</th>\n",
       "      <th>Percentage of Part-time employees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E05000026</td>\n",
       "      <td>136.609508</td>\n",
       "      <td>19.60720</td>\n",
       "      <td>2.164412</td>\n",
       "      <td>17.1</td>\n",
       "      <td>175.0</td>\n",
       "      <td>15.195767</td>\n",
       "      <td>525.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>8.525224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>70.489156</td>\n",
       "      <td>24.526996</td>\n",
       "      <td>4.983849</td>\n",
       "      <td>65.822785</td>\n",
       "      <td>34.177215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E05000027</td>\n",
       "      <td>181.278351</td>\n",
       "      <td>22.41290</td>\n",
       "      <td>71.727362</td>\n",
       "      <td>22.7</td>\n",
       "      <td>150.0</td>\n",
       "      <td>19.040541</td>\n",
       "      <td>595.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>8.622620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63.276620</td>\n",
       "      <td>26.381189</td>\n",
       "      <td>10.342191</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E05000028</td>\n",
       "      <td>310.103636</td>\n",
       "      <td>3.03888</td>\n",
       "      <td>17.166271</td>\n",
       "      <td>20.1</td>\n",
       "      <td>175.0</td>\n",
       "      <td>16.910180</td>\n",
       "      <td>590.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>9.123722</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.226763</td>\n",
       "      <td>25.383687</td>\n",
       "      <td>9.389550</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>54.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E05000029</td>\n",
       "      <td>254.118297</td>\n",
       "      <td>56.40730</td>\n",
       "      <td>63.592351</td>\n",
       "      <td>21.1</td>\n",
       "      <td>115.0</td>\n",
       "      <td>14.816327</td>\n",
       "      <td>435.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>7.688611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>59.984065</td>\n",
       "      <td>24.519470</td>\n",
       "      <td>15.496464</td>\n",
       "      <td>52.941176</td>\n",
       "      <td>47.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E05000030</td>\n",
       "      <td>201.110643</td>\n",
       "      <td>51.11650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.8</td>\n",
       "      <td>95.0</td>\n",
       "      <td>11.861635</td>\n",
       "      <td>340.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>8.021933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.223236</td>\n",
       "      <td>21.087659</td>\n",
       "      <td>14.689104</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>27.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>E05011485</td>\n",
       "      <td>229.847122</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>E05011486</td>\n",
       "      <td>266.757530</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>E05011487</td>\n",
       "      <td>491.851936</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>E05011488</td>\n",
       "      <td>252.618917</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>E05011489</td>\n",
       "      <td>432.814952</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        osward    QUANTITY  Area that is greenspace  \\\n",
       "0    E05000026  136.609508                 19.60720   \n",
       "1    E05000027  181.278351                 22.41290   \n",
       "2    E05000028  310.103636                  3.03888   \n",
       "3    E05000029  254.118297                 56.40730   \n",
       "4    E05000030  201.110643                 51.11650   \n",
       "..         ...         ...                      ...   \n",
       "579  E05011485  229.847122                  0.00000   \n",
       "580  E05011486  266.757530                  0.00000   \n",
       "581  E05011487  491.851936                  0.00000   \n",
       "582  E05011488  252.618917                  0.00000   \n",
       "583  E05011489  432.814952                  0.00000   \n",
       "\n",
       "     Percentage homes with deficiency in access to nature  \\\n",
       "0                                             2.164412      \n",
       "1                                            71.727362      \n",
       "2                                            17.166271      \n",
       "3                                            63.592351      \n",
       "4                                             0.000000      \n",
       "..                                                 ...      \n",
       "579                                           0.000000      \n",
       "580                                           0.000000      \n",
       "581                                           0.000000      \n",
       "582                                           0.000000      \n",
       "583                                           0.000000      \n",
       "\n",
       "     DWP Working-age client group (rates)  \\\n",
       "0                                    17.1   \n",
       "1                                    22.7   \n",
       "2                                    20.1   \n",
       "3                                    21.1   \n",
       "4                                    16.8   \n",
       "..                                    ...   \n",
       "579                                   0.0   \n",
       "580                                   0.0   \n",
       "581                                   0.0   \n",
       "582                                   0.0   \n",
       "583                                   0.0   \n",
       "\n",
       "     Employment and support allowance claimants  Housing Benefit rates  \\\n",
       "0                                         175.0              15.195767   \n",
       "1                                         150.0              19.040541   \n",
       "2                                         175.0              16.910180   \n",
       "3                                         115.0              14.816327   \n",
       "4                                          95.0              11.861635   \n",
       "..                                          ...                    ...   \n",
       "579                                         0.0               0.000000   \n",
       "580                                         0.0               0.000000   \n",
       "581                                         0.0               0.000000   \n",
       "582                                         0.0               0.000000   \n",
       "583                                         0.0               0.000000   \n",
       "\n",
       "     Income Support Claimants  Incapacity Benefit Claimants  \\\n",
       "0                       525.0                         305.0   \n",
       "1                       595.0                         395.0   \n",
       "2                       590.0                         440.0   \n",
       "3                       435.0                         330.0   \n",
       "4                       340.0                         260.0   \n",
       "..                        ...                           ...   \n",
       "579                       0.0                           0.0   \n",
       "580                       0.0                           0.0   \n",
       "581                       0.0                           0.0   \n",
       "582                       0.0                           0.0   \n",
       "583                       0.0                           0.0   \n",
       "\n",
       "     JSA Claimant Rate  ...  outdoor_count  pub_count  skate_count  \\\n",
       "0             8.525224  ...            0.0        6.0          0.0   \n",
       "1             8.622620  ...            0.0        1.0          0.0   \n",
       "2             9.123722  ...            0.0        0.0          0.0   \n",
       "3             7.688611  ...            0.0        5.0          0.0   \n",
       "4             8.021933  ...            0.0        2.0          0.0   \n",
       "..                 ...  ...            ...        ...          ...   \n",
       "579           0.000000  ...            0.0        8.0          1.0   \n",
       "580           0.000000  ...            0.0        2.0          0.0   \n",
       "581           0.000000  ...            0.0        3.0          1.0   \n",
       "582           0.000000  ...            0.0        3.0          0.0   \n",
       "583           0.000000  ...            0.0        4.0          0.0   \n",
       "\n",
       "     theatre_count  total_count  Aged 16-64 Percentage  Aged 0-15 Percentage  \\\n",
       "0              1.0         13.0              70.489156             24.526996   \n",
       "1              0.0          1.0              63.276620             26.381189   \n",
       "2              0.0          1.0              65.226763             25.383687   \n",
       "3              0.0          7.0              59.984065             24.519470   \n",
       "4              0.0          2.0              64.223236             21.087659   \n",
       "..             ...          ...                    ...                   ...   \n",
       "579            1.0         11.0               0.000000              0.000000   \n",
       "580            0.0          2.0               0.000000              0.000000   \n",
       "581            0.0          4.0               0.000000              0.000000   \n",
       "582            0.0          3.0               0.000000              0.000000   \n",
       "583            0.0          4.0               0.000000              0.000000   \n",
       "\n",
       "     Aged 65+ Percentage  Percentage of Full-time employees  \\\n",
       "0               4.983849                          65.822785   \n",
       "1              10.342191                          50.000000   \n",
       "2               9.389550                          45.454545   \n",
       "3              15.496464                          52.941176   \n",
       "4              14.689104                          72.500000   \n",
       "..                   ...                                ...   \n",
       "579             0.000000                           0.000000   \n",
       "580             0.000000                           0.000000   \n",
       "581             0.000000                           0.000000   \n",
       "582             0.000000                           0.000000   \n",
       "583             0.000000                           0.000000   \n",
       "\n",
       "     Percentage of Part-time employees  \n",
       "0                            34.177215  \n",
       "1                            50.000000  \n",
       "2                            54.545455  \n",
       "3                            47.058824  \n",
       "4                            27.500000  \n",
       "..                                 ...  \n",
       "579                           0.000000  \n",
       "580                           0.000000  \n",
       "581                           0.000000  \n",
       "582                           0.000000  \n",
       "583                           0.000000  \n",
       "\n",
       "[584 rows x 29 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset_confounders_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get same results as in results2\n",
    "\n",
    "def get_treatment_level(input, bins):\n",
    "    if input < bins[0]:\n",
    "        return 0\n",
    "    elif input < bins[1]:\n",
    "        return 1\n",
    "    elif input < bins[2]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def logit(p):\n",
    "    logit_value = math.log(p / (1-p))\n",
    "    return logit_value\n",
    "\n",
    "def plot_propensity_plots(predictions, predictions_logit, T):\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    fig.suptitle('Density distribution plots for propensity score and logit(propensity score).')\n",
    "    sns.kdeplot(x = predictions[:,1], hue = T , ax = ax[0])\n",
    "    ax[0].set_title('Propensity Score')\n",
    "    sns.kdeplot(x = predictions_logit, hue = T , ax = ax[1])\n",
    "    ax[1].axvline(-0.4, ls='--')\n",
    "    ax[1].set_title('Logit of Propensity Score')\n",
    "    plt.show()\n",
    "\n",
    "def create_maximum_branching_graph(df_data):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(df_data.reset_index()['osward'].tolist())\n",
    "    df_data_no_index = df_data.reset_index()\n",
    "    epsilon = 0.0001\n",
    "    for index, row in df_data_no_index.iterrows():\n",
    "        other_rows = df_data_no_index[df_data_no_index['treatment'] != row.treatment]\n",
    "        for o_index, o_row in other_rows.reset_index().iterrows():\n",
    "            if not G.has_edge(row.osward, o_row.osward):\n",
    "                modified_distance = (abs(row.propensity_score_logit - o_row.propensity_score_logit) + epsilon) / abs(row.treatment - o_row.treatment)\n",
    "                G.add_edge(row.osward, o_row.osward, weight=modified_distance)\n",
    "    return maximum_branching(G)\n",
    "\n",
    "def plot_correlation(input_data, treatment_column):\n",
    "    correlation = input_data[[treatment_column, 'outcome']]\n",
    "    correlation.plot.scatter(x=treatment_column, y='outcome')\n",
    "    spear_corr = stats.spearmanr(list(correlation[treatment_column]), list(correlation['outcome']))\n",
    "    print('Spearman correlation:', spear_corr.correlation, 'p-value:', spear_corr.pvalue)\n",
    "\n",
    "def plot_distance_distribution(edmonds_applied, df_data):\n",
    "    distances = []\n",
    "    treatment_effect = []\n",
    "    for (u,v) in edmonds_applied.edges():\n",
    "        distances.append(abs(df_data['treatment'][u] - df_data['treatment'][v]))\n",
    "        effect = (df_data['outcome'][u] - df_data['outcome'][v])/(df_data['treatment'][u] - df_data['treatment'][v])\n",
    "        treatment_effect.append(effect)\n",
    "    distribution_data = pd.DataFrame(list(zip(distances,treatment_effect)), columns = ['Distance', 'Effect'])\n",
    "    sns.jointplot(distribution_data, x='Distance', y='Effect', kind='kde', fill=True)\n",
    "\n",
    "def print_distance_confusion_matrix(edmonds_applied, df_data):\n",
    "    low_dose_units = []\n",
    "    high_dose_units = []\n",
    "\n",
    "    for (u,v) in edmonds_applied.edges():\n",
    "        u_treatment = df_data['treatment'][u]\n",
    "        v_treatment = df_data['treatment'][v]\n",
    "        if u_treatment > v_treatment:\n",
    "            low_dose_units.append(v_treatment)\n",
    "            high_dose_units.append(u_treatment)\n",
    "            continue\n",
    "        low_dose_units.append(u_treatment)\n",
    "        high_dose_units.append(v_treatment)\n",
    "\n",
    "    print(confusion_matrix(high_dose_units, low_dose_units))\n",
    "\n",
    "def obtain_results(input_data, treatment_column, outcome_column, columns_to_drop, bins):\n",
    "    df = input_data.copy()\n",
    "    subset = df.drop(columns_to_drop, axis=1)\n",
    "    df[treatment_column] = df[treatment_column].astype('int')\n",
    "    subset[treatment_column] = subset[treatment_column].astype('int')\n",
    "    treatment_levels = [get_treatment_level(x, bins) for x in list(df[treatment_column])]\n",
    "    subset_treatment_levels = [get_treatment_level(x, bins) for x in list(subset[treatment_column])]\n",
    "    df[treatment_column + '_bin'] = treatment_levels\n",
    "    subset[treatment_column] = subset_treatment_levels\n",
    "\n",
    "    T = subset[treatment_column]\n",
    "    X = subset.loc[:,subset.columns != treatment_column]\n",
    "    y = input_data[[outcome_column]]\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('logistic_classifier', lr())\n",
    "    ])\n",
    "    pipe.fit(X, T)\n",
    "\n",
    "    predictions = pipe.predict_proba(X)\n",
    "    predictions_binary = pipe.predict(X)\n",
    "    predictions_logit = np.array([logit(xi) for xi in predictions[:,1]])\n",
    "    df.loc[:,'propensity_score'] = predictions[:,1]\n",
    "    df.loc[:,'propensity_score_logit'] = predictions_logit\n",
    "    df.loc[:,'outcome'] = y[outcome_column]\n",
    "\n",
    "    X.loc[:,'propensity_score'] = predictions[:,1]\n",
    "    X.loc[:,'propensity_score_logit'] = predictions_logit\n",
    "    X.loc[:,'outcome'] = y[outcome_column]\n",
    "    X.loc[:,'treatment'] = df[treatment_column + '_bin']\n",
    "\n",
    "    caliper = np.std(df.propensity_score) * 0.25\n",
    "    # print('\\nCaliper (radius) is: {:.4f}\\n'.format(caliper))\n",
    "\n",
    "    df_data = X\n",
    "    knn = NearestNeighbors(n_neighbors=10 , p = 2, radius=caliper)\n",
    "    knn.fit(df_data[['propensity_score_logit']].to_numpy())\n",
    "    \n",
    "    distances , indexes = knn.kneighbors(\n",
    "        df_data[['propensity_score_logit']].to_numpy(), \\\n",
    "        n_neighbors=10)\n",
    "    df_data['osward'] = range(1, len(df_data) + 1)\n",
    "    df_data.osward = 'E' + df_data.osward.astype(str)\n",
    "    df_data.set_index('osward', inplace=True)\n",
    "\n",
    "    edmonds_applied = create_maximum_branching_graph(df_data)\n",
    "    treatment_effect = []\n",
    "    for (u,v) in edmonds_applied.edges():\n",
    "        effect = (df_data['outcome'][u] - df_data['outcome'][v])/(df_data['treatment'][u] - df_data['treatment'][v])\n",
    "        treatment_effect.append(effect)\n",
    "    return treatment_effect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for generating data\n",
    "\n",
    "def get_truncnorm_generated(dataset, size):\n",
    "    a = dataset.min()\n",
    "    b = dataset.max()\n",
    "    mu = dataset.mean()\n",
    "    sigma = dataset.std()\n",
    "    return stats.truncnorm.rvs(a, b, loc=mu, scale=sigma, size=size)\n",
    "\n",
    "def get_exponential_generated(dataset, size):\n",
    "    mu = dataset.mean()\n",
    "    sigma = dataset.std()\n",
    "    return stats.expon.rvs(loc=mu, scale=sigma, size=size)\n",
    "\n",
    "def get_exponential_treatment_generated(row, a = 200):\n",
    "    scale = row.sum() / a\n",
    "    return stats.expon.rvs(loc = 0, scale=scale, size=1)[0]\n",
    "\n",
    "def get_truncated_outcome_generated(row, confounders, a = 0.000015, b = 100, ate = -1):\n",
    "    alpha = a * confounders.sum()\n",
    "    beta = b * confounders.sum()\n",
    "    mu = confounders.mean()\n",
    "    sigma = confounders.std()\n",
    "    return max(stats.truncnorm.rvs(a = alpha, b = beta, loc = mu, scale = sigma, size=1)[0] + ate * row['treatment'], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_averages(effects, amt):\n",
    "    ate = 0\n",
    "    minimum = 0\n",
    "    percentile_25 = 0\n",
    "    percentile_75 = 0\n",
    "    maximum = 0\n",
    "    for eff in effects:\n",
    "        ate += np.mean(eff)\n",
    "        minimum += np.min(eff)\n",
    "        percentile_25 += np.percentile(eff,25)\n",
    "        percentile_75 += np.percentile(eff,75)\n",
    "        maximum += np.max(eff)\n",
    "    print('ATE:', ate/amt, 'Min:', minimum/amt,'25th %:', percentile_25/amt, '75th %:', percentile_75/amt, 'Max:', maximum/amt)\n",
    "\n",
    "\n",
    "def get_average_treatment_over_runs(dataset, ate= -1, runs=10):\n",
    "    simulated_dfs = []\n",
    "\n",
    "    for _ in range(runs):\n",
    "        age1664_generated = np.array(get_truncnorm_generated(dataset['Aged 16-64 Percentage'], 625))\n",
    "        age015_generated = np.array(get_truncnorm_generated(dataset['Aged 0-15 Percentage'], 625))\n",
    "        age65plus_generated = np.array(get_truncnorm_generated(dataset['Aged 65+ Percentage'], 625))\n",
    "        percentage_greenspace_generated = np.array(get_truncnorm_generated(dataset[\"Area that is greenspace\"], 625))\n",
    "        percentage_working_age_rates = np.array(get_truncnorm_generated(dataset[\"DWP Working-age client group (rates)\"], 625))\n",
    "        employment_support_claimants = np.array(get_truncnorm_generated(dataset[\"Employment and support allowance claimants\"], 625))\n",
    "        housing_benefit_rates = np.array(get_truncnorm_generated(dataset[\"Housing Benefit rates\"], 625))\n",
    "        income_support_claimants = np.array(get_truncnorm_generated(dataset[\"Income Support Claimants\"], 625))\n",
    "        incapacity_benefit_claimants = np.array(get_truncnorm_generated(dataset[\"Incapacity Benefit Claimants\"], 625))\n",
    "        jsa_claimant_rate = np.array(get_truncnorm_generated(dataset[\"JSA Claimant Rate\"], 625))\n",
    "\n",
    "        full_time_employees = np.array(get_exponential_generated(dataset[\"Percentage of Full-time employees\"], 625))\n",
    "        part_time_employees = np.array(get_exponential_generated(dataset[\"Percentage of Part-time employees\"], 625))\n",
    "        deficiency_access_nature = np.array(get_exponential_generated(dataset[\"Percentage homes with deficiency in access to nature\"], 625))\n",
    "        \n",
    "        simulated_confounders = [age1664_generated, age015_generated, age65plus_generated, percentage_greenspace_generated, percentage_working_age_rates, employment_support_claimants, housing_benefit_rates, income_support_claimants, incapacity_benefit_claimants, jsa_claimant_rate, full_time_employees, part_time_employees, deficiency_access_nature]\n",
    "        simulated_confounders_df = pd.DataFrame(simulated_confounders).transpose()\n",
    "        confounders = ['Aged 16-64 Percentage', 'Aged 0-15 Percentage', 'Aged 65+ Percentage', \"Area that is greenspace\", \"DWP Working-age client group (rates)\", \"Employment and support allowance claimants\", \"Housing Benefit rates\", \"Income Support Claimants\",\n",
    "            \"Incapacity Benefit Claimants\", \"JSA Claimant Rate\", \"Percentage of Part-time employees\", \"Percentage of Full-time employees\", \"Percentage homes with deficiency in access to nature\"]\n",
    "        simulated_confounders_df.columns = confounders\n",
    "        simulated_confounders_df['treatment'] = simulated_confounders_df.apply(lambda row: get_exponential_treatment_generated(row), axis=1)\n",
    "        simulated_confounders_df['outcome'] = simulated_confounders_df.apply(lambda row: get_truncated_outcome_generated(row, row[confounders], ate=ate), axis=1)\n",
    "        simulated_dfs.append(simulated_confounders_df)\n",
    "    effects = []\n",
    "    for simulated_df in simulated_dfs:\n",
    "        effects.append(obtain_results(simulated_df, 'treatment', 'outcome', ['outcome'], bins=[4,7,12]))\n",
    "    calculate_averages(effects, runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_average_treatment_over_runs(full_dataset_confounders_2012, ate=-1, runs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
